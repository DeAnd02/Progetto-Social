{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Script che converte ogni entry dei file json di una cartella (che è in una singola riga) in un file formattato correttamente"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7582d218181ad0be"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# seleziono la cartella coi vari file json di una giornata, in questo caso 12 novembre 2022\n",
    "cartella_input= \"C:\\\\Users\\\\andre\\\\Desktop\\\\Progetto Social\\\\20221112\"\n",
    "\n",
    "# Ottieni la lista di file nella cartella\n",
    "files = [f for f in os.listdir(cartella_input) if os.path.isfile(os.path.join(cartella_input, f))]\n",
    "\n",
    "# Apri il file di output in modalità scrittura\n",
    "n_file = 0\n",
    "for file_name in files:\n",
    "    # Costruisci il percorso completo del file\n",
    "    file_path = os.path.join(cartella_input, file_name)\n",
    "\n",
    "    filename = file_path\n",
    "\n",
    "    # Leggi il file come stringa\n",
    "    with open(filename, 'r',  encoding='utf-8') as f:\n",
    "        input_str = f.read()\n",
    "    \n",
    "    # Dividi la stringa di input in linee\n",
    "    lines = input_str.strip().split('\\n')\n",
    "    \n",
    "    # Converti ogni linea in un dizionario e mettili in una lista\n",
    "    data_list = [json.loads(line) for line in lines]\n",
    "    \n",
    "    # Sovrascrivi la lista di dizionari sullo stesso file JSON\n",
    "    with open(filename, 'w',  encoding='utf-8') as f:\n",
    "        json.dump(data_list, f, indent=2)\n",
    "    \n",
    "    # stampa utilizzata per vedere a che numero di file fosse arrivata l'esecuzione\n",
    "    n_file += 1\n",
    "    print(n_file)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b617cfc814af055"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Script utilizzato per eliminare tutte le colonne superflue alla nostra analisi\n",
    "Nello script andiamo anche ad unire tutti i file di una giornata in un unico json"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "567dc46facdee17c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "''' SCRIPT TO DELETE COLUMNS'''\n",
    "import json\n",
    "import os\n",
    "\n",
    "# seleziono la cartella coi vari file json di una giornata, in questo caso 12 novembre 2022\n",
    "cartella_input= \"C:\\\\Users\\\\andre\\\\Desktop\\\\Progetto Social\\\\20221112\"\n",
    "\n",
    "# Ottieni la lista di file nella cartella\n",
    "files = [f for f in os.listdir(cartella_input) if os.path.isfile(os.path.join(cartella_input, f))]\n",
    "\n",
    "# final_file sarà la lista di dizionari che conterrà tutti i tweet di tutti i file\n",
    "final_file = []\n",
    "#numero del file a cui è arrivata la computazione\n",
    "n_file = 0\n",
    "# iterazione tra i file di una cartella\n",
    "for file_name in files:\n",
    "    # Costruisci il percorso completo del file\n",
    "    file_path = os.path.join(cartella_input, file_name)\n",
    "    \n",
    "    '''sezione pulizia file'''\n",
    "    # Apri il file corrente in modalità lettura\n",
    "    with open(file_path, 'r') as input_file:\n",
    "        # Leggi il contenuto del file e scrivilo nel file di output\n",
    "        data = json.load(input_file)\n",
    "        \n",
    "    # lista di colonne da eliminare\n",
    "    var = ['utc_offset','time_zone','profile_background_color','profile_background_image_url','profile_background_image_url_https','profile_background_tile','profile_link_color','profile_sidebar_border_color','profile_sidebar_fill_color','profile_text_color','profile_use_background_image', 'profile_image_url','profile_image_url_https','profile_banner_url','default_profile','default_profile_image','follow_request_sent','notifications','withheld_in_countries','filter_level','truncated','timestamp_ms','favorite_count','quote_count','is_quote_status','contributors','place','coordinates','source','id_str','in_reply_to_status_id','in_reply_to_status_id_str','in_reply_to_user_id','in_reply_to_user_id_str','in_reply_to_screen_name', 'quoted_status_id','quoted_status_id_str','quoted_status_permalink','geo','display_text_range','extended_tweet','extended_entities','quoted_status','possibly_sensitive']\n",
    "    \n",
    "    # Rimuovi la colonna\n",
    "    for item in data:\n",
    "        # delle entities salvo solo hashtags e menzioni di utenti\n",
    "        if 'entities' in item:\n",
    "            item['hashtags'] = item['entities']['hashtags']\n",
    "            item['user_mentions'] = item['entities']['user_mentions']\n",
    "        else:\n",
    "            item['hashtags'] = []\n",
    "            item['user_mentions'] = []\n",
    "        # salvo il testo completo del tweet\n",
    "        if 'extended_tweet' in item:\n",
    "            item['text'] = item['extended_tweet']['full_text']\n",
    "            if 'entities' in item['extended_tweet']:\n",
    "                item['hashtags'] = item['extended_tweet']['entities']['hashtags']\n",
    "                item['user_mentions'] = item['extended_tweet']['entities']['user_mentions']\n",
    "        else:\n",
    "            item['text'] = item['text']\n",
    "        # salvo i dati dell'utente importanti per l'analisi\n",
    "        if 'user' in item:\n",
    "            item['user_id'] = item['user']['id']\n",
    "            item['user_name'] = item['user']['name']\n",
    "            item['user_screenname'] = item['user']['screen_name']\n",
    "            item['user_followers_count'] = item['user']['followers_count']\n",
    "            del item['user']\n",
    "        # salvo l'id del tweet originale se è un retweet\n",
    "        if 'retweeted_status' in item:\n",
    "            item['retweet_parent_id'] = item['retweeted_status']['id']\n",
    "            del item['retweeted_status']\n",
    "        else:\n",
    "            item['retweet_parent_id'] = -1\n",
    "        #elimino tutte le entities nella lista var\n",
    "        for var_to_delete in var:\n",
    "            if var_to_delete in item:\n",
    "                del item[var_to_delete]\n",
    "        # aggiungo il tweet alla lista finale\n",
    "        final_file.append(item)\n",
    "    # stampa utilizzata per vedere a che numero di file fosse arrivata l'esecuzione\n",
    "    n_file += 1\n",
    "    print(n_file)\n",
    "    \n",
    "# scrivo il file finale\n",
    "with open('file_finale.json', 'w') as f:\n",
    "    json.dump(final_file, f,indent=2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90ea40f417ed980a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Script per filtrare i tweet in base alla lingua e alle parole chiave riguardo il nucleare"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cedb0335785b41f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "import langid\n",
    "import os\n",
    "\n",
    "# cartella dove sono contenuti tutti i file di tutti i giorni\n",
    "cartella_input= \"C:\\\\Users\\\\andre\\\\Desktop\\\\Progetto Social\\\\files\"\n",
    "\n",
    "# Ottieni la lista di file nella cartella\n",
    "files = [f for f in os.listdir(cartella_input) if os.path.isfile(os.path.join(cartella_input, f))]\n",
    "# liste delle parole chiavi selezionate per singola lingua\n",
    "parole_chiave_inglese = [\n",
    "    \"radioactivity\",\n",
    "    \"nuclear fission\",\n",
    "    \"isotopes\",\n",
    "    \"nuclear military\",\n",
    "    \"atomic energy\",\n",
    "    \"nuclear energy\",\n",
    "    \"graphite\",\n",
    "    \"nuclear risks\",\n",
    "    \"nuclear proliferation\",\n",
    "    \"nuclear accident\",\n",
    "    \"Chernobyl\",\n",
    "    \"Fukushima\",\n",
    "    \"nuclear waste\",\n",
    "    \"nuclear disarmament\",\n",
    "    \"nuclear deterrence\",\n",
    "    \"nuclear test\",\n",
    "    \"nuclear agreement\",\n",
    "    \"nuclear radiation\",\n",
    "    \"management of nuclear waste\",\n",
    "    \"national nuclear programs\",\n",
    "    \"sustainable nuclear energy\",\n",
    "    \"international nuclear negotiations\"\n",
    "]\n",
    "parole_chiave_portoghese = [\n",
    "    \"radioatividade\",\n",
    "    \"fissão nuclear\",\n",
    "    \"isótopos\",\n",
    "    \"militar nuclear\",\n",
    "    \"energia atômica\",\n",
    "    \"energia nuclear\",\n",
    "    \"grafite\",\n",
    "    \"riscos nucleares\",\n",
    "    \"proliferação nuclear\",\n",
    "    \"acidente nuclear\",\n",
    "    \"Chernobyl\",\n",
    "    \"Fukushima\",\n",
    "    \"resíduos nucleares\",\n",
    "    \"desarmamento nuclear\",\n",
    "    \"dissuasão nuclear\",\n",
    "    \"teste nuclear\",\n",
    "    \"acordo nuclear\",\n",
    "    \"radiação nuclear\",\n",
    "    \"gestão de resíduos nucleares\",\n",
    "    \"programas nucleares nacionais\",\n",
    "    \"energia nuclear sustentável\",\n",
    "    \"negociações nucleares internacionais\"\n",
    "]\n",
    "parole_chiave_tedesco = [\n",
    "    \"Radioaktivität\",\n",
    "    \"Nukleare Spaltung\",\n",
    "    \"Isotope\",\n",
    "    \"Nukleare Militär\",\n",
    "    \"Atomenergie\",\n",
    "    \"Nukleare Energie\",\n",
    "    \"Graphit\",\n",
    "    \"Nukleare Risiken\",\n",
    "    \"Nukleare Proliferation\",\n",
    "    \"Nuklearer Unfall\",\n",
    "    \"Tschernobyl\",\n",
    "    \"Fukushima\",\n",
    "    \"Nuklearer Abfall\",\n",
    "    \"Nukleare Abrüstung\",\n",
    "    \"Nukleare Abschreckung\",\n",
    "    \"Nukleartest\",\n",
    "    \"Nuklearabkommen\",\n",
    "    \"Nukleare Strahlung\",\n",
    "    \"Management von Nuklearabfällen\",\n",
    "    \"Nationale Nuklearprogramme\",\n",
    "    \"Nachhaltige Nuklearenergie\",\n",
    "    \"Internationale Nuklearverhandlungen\"\n",
    "]\n",
    "parole_chiave_spagnole = [\n",
    "    \"radioactividad\",\n",
    "    \"fisión nuclear\",\n",
    "    \"isótopos\",\n",
    "    \"militar nuclear\",\n",
    "    \"energía atómica\",\n",
    "    \"energía nuclear\",\n",
    "    \"grafito\",\n",
    "    \"riesgos nucleares\",\n",
    "    \"proliferación nuclear\",\n",
    "    \"accidente nuclear\",\n",
    "    \"Chernobyl\",\n",
    "    \"Fukushima\",\n",
    "    \"residuos nucleares\",\n",
    "    \"desarme nuclear\",\n",
    "    \"disuasión nuclear\",\n",
    "    \"prueba nuclear\",\n",
    "    \"acuerdo nuclear\",\n",
    "    \"radiación nuclear\",\n",
    "    \"gestión de residuos nucleares\",\n",
    "    \"programas nucleares nacionales\",\n",
    "    \"energía nuclear sostenible\",\n",
    "    \"negociaciones nucleares internacionales\"\n",
    "]\n",
    "parole_chiave_italiano = [\n",
    "    \"radioattività\",\n",
    "    \"fissione nucleare\",\n",
    "    \"isotopi\",\n",
    "    \"militare nucleare\",\n",
    "    \"energia atomica\",\n",
    "    \"energia nucleare\",\n",
    "    \"grafite\",\n",
    "    \"rischi nucleari\",\n",
    "    \"proliferazione nucleare\",\n",
    "    \"incidente nucleare\",\n",
    "    \"Chernobyl\",\n",
    "    \"Fukushima\",\n",
    "    \"rifiuti nucleari\",\n",
    "    \"disarmo nucleare\",\n",
    "    \"dissuasione nucleare\",\n",
    "    \"test nucleare\",\n",
    "    \"accordo nucleare\",\n",
    "    \"radiazione nucleare\",\n",
    "    \"gestione dei rifiuti nucleari\",\n",
    "    \"programmi nucleari nazionali\",\n",
    "    \"energia nucleare sostenibile\",\n",
    "    \"negoziazioni nucleari internazionali\"\n",
    "]\n",
    "parole_chiave_francese = [\n",
    "    \"radioactivité\",\n",
    "    \"fission nucléaire\",\n",
    "    \"isotopes\",\n",
    "    \"militaire nucléaire\",\n",
    "    \"énergie atomique\",\n",
    "    \"énergie nucléaire\",\n",
    "    \"graphite\",\n",
    "    \"risques nucléaires\",\n",
    "    \"prolifération nucléaire\",\n",
    "    \"accident nucléaire\",\n",
    "    \"Tchernobyl\",\n",
    "    \"Fukushima\",\n",
    "    \"déchets nucléaires\",\n",
    "    \"désarmement nucléaire\",\n",
    "    \"dissuasion nucléaire\",\n",
    "    \"essai nucléaire\",\n",
    "    \"accord nucléaire\",\n",
    "    \"radiation nucléaire\",\n",
    "    \"gestion des déchets nucléaires\",\n",
    "    \"programmes nucléaires nationaux\",\n",
    "    \"énergie nucléaire durable\",\n",
    "    \"négociations nucléaires internationales\"\n",
    "]\n",
    "\n",
    "# liste dei tweet filtrati per lingua\n",
    "tweet_filtrati_inglese = []\n",
    "tweet_filtrati_portoghese = []\n",
    "tweet_filtrati_tedesco = []\n",
    "tweet_filtrati_spagnolo = []\n",
    "tweet_filtrati_italiano = []\n",
    "tweet_filtrati_francese = []\n",
    "\n",
    "# iterazione tra i file di una cartella\n",
    "for file_name in files:\n",
    "    # per semplicità di calcolo eseguiamo un il codice singolarmente per file, qui è selezionato il giorno 13 novembre 2022\n",
    "    if file_name==\"1113.json\":\n",
    "        file_path = os.path.join(cartella_input, file_name)\n",
    "        with open(file_path, 'r') as input_file:\n",
    "                # Leggi il contenuto del file e lo salva in data\n",
    "                data = json.load(input_file)\n",
    "        for item in data:\n",
    "            # riconoscimento della lingua del tweet\n",
    "            lingua, _ = langid.classify(item['text'])\n",
    "            print(lingua)\n",
    "            \n",
    "            # Applica le parole chiave solo ai tweet per la lingua riconosciuta, va a rendere tutti i caratteri maiuscoli in minuscoli\n",
    "            match lingua:\n",
    "                case 'en':\n",
    "                    if any(parola.lower() in item['text'].lower() for parola in parole_chiave_inglese):\n",
    "                        tweet_filtrati_inglese.append(item)\n",
    "                case 'pt':\n",
    "                    if any(parola.lower() in item['text'].lower() for parola in parole_chiave_portoghese):\n",
    "                        tweet_filtrati_portoghese.append(item)\n",
    "                case 'de':\n",
    "                    if any(parola.lower() in item['text'].lower() for parola in parole_chiave_tedesco):\n",
    "                        tweet_filtrati_tedesco.append(item)\n",
    "                case 'es':\n",
    "                    if any(parola.lower() in item['text'].lower() for parola in parole_chiave_spagnole):\n",
    "                        tweet_filtrati_spagnolo.append(item)\n",
    "                case 'it':\n",
    "                    if any(parola.lower() in item['text'].lower() for parola in parole_chiave_italiano):\n",
    "                        tweet_filtrati_italiano.append(item)\n",
    "                case 'fr':\n",
    "                    if any(parola.lower() in item['text'].lower() for parola in parole_chiave_francese):\n",
    "                        tweet_filtrati_francese.append(item)\n",
    "    \n",
    "# scrivo i file filtrati\n",
    "with open('en.json', 'w') as f1:\n",
    "    json.dump(tweet_filtrati_inglese, f1,indent=2)\n",
    "    f1.close()\n",
    "with open('pt.json', 'w') as f2:\n",
    "    json.dump(tweet_filtrati_portoghese, f2,indent=2)\n",
    "    f2.close()\n",
    "with open('de.json', 'w') as f3:\n",
    "    json.dump(tweet_filtrati_tedesco, f3,indent=2)\n",
    "    f3.close()\n",
    "with open('es.json', 'w') as f4:\n",
    "    json.dump(tweet_filtrati_spagnolo, f4,indent=2)\n",
    "    f4.close()\n",
    "with open('it.json', 'w') as f5:\n",
    "    json.dump(tweet_filtrati_italiano, f5,indent=2)\n",
    "    f5.close()\n",
    "with open('fr.json', 'w') as f6:\n",
    "    json.dump(tweet_filtrati_francese, f6,indent=2)\n",
    "    f6.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b43b3cd7f961d25"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Script per unire i file filtrati di ogni singolo giorno in un unico file per lingua"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3e3d48eedcd1a8c"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "'''Unire i files'''\n",
    "import json\n",
    "import os\n",
    "\n",
    "# cartella dove sono contenuti tutti i file di tutti i giorni filtrati\n",
    "cartella_input= \"C:\\\\Users\\\\andre\\\\PycharmProjects\\\\Progetto-Social\\\\filtered\"\n",
    "\n",
    "# Ottieni la lista di file nella cartella\n",
    "dirs = [d for d in os.listdir(cartella_input) if os.path.isdir(os.path.join(cartella_input, d))]\n",
    "\n",
    "inglese = []\n",
    "portoghese = []\n",
    "tedesco = []\n",
    "spagnolo = []\n",
    "italiano = []\n",
    "francese = []\n",
    "\n",
    "# iterazione tra le cartelle delle giornate\n",
    "for dir in dirs:\n",
    "    folder_name = os.path.join(cartella_input, dir)\n",
    "    files = [f for f in os.listdir(folder_name) if os.path.isfile(os.path.join(folder_name, f))] \n",
    "\n",
    "    # iterazione tra i file di una cartella del giorno\n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_name, file)\n",
    "        with open(file_path, 'r') as input_file:\n",
    "                # Leggi il contenuto del file e scrivilo nel file di output\n",
    "                data = json.load(input_file)\n",
    "        # iterazione tra i tweet di un file\n",
    "        for item in data:\n",
    "            # inserisco i dati della lingua del file corrispondente\n",
    "            match file:\n",
    "                case \"en.json\":\n",
    "                    inglese.append(item)\n",
    "                case \"pt.json\":\n",
    "                    portoghese.append(item)\n",
    "                case \"de.json\":\n",
    "                    tedesco.append(item)\n",
    "                case \"es.json\":\n",
    "                    spagnolo.append(item)\n",
    "                case \"it.json\":\n",
    "                    italiano.append(item)\n",
    "                case \"fr.json\":\n",
    "                    francese.append(item)\n",
    "                \n",
    "# scrivo i file finali\n",
    "with open('inglese.json', 'w') as f1:\n",
    "    json.dump(inglese, f1,indent=2)\n",
    "    f1.close()\n",
    "with open('portoghese.json', 'w') as f2:\n",
    "    json.dump(portoghese, f2,indent=2)\n",
    "    f2.close()\n",
    "with open('tedesco.json', 'w') as f3:\n",
    "    json.dump(tedesco, f3,indent=2)\n",
    "    f3.close()\n",
    "with open('spagnolo.json', 'w') as f4:\n",
    "    json.dump(spagnolo, f4,indent=2)\n",
    "    f4.close()\n",
    "with open('italiano.json', 'w') as f5:\n",
    "    json.dump(italiano, f5,indent=2)\n",
    "    f5.close()\n",
    "with open('francese.json', 'w') as f6:\n",
    "    json.dump(francese, f6,indent=2)\n",
    "    f6.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T20:02:35.360537300Z",
     "start_time": "2024-01-09T20:02:33.070538Z"
    }
   },
   "id": "e11a75eb33b53a5e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Script per convertire i file json in csv"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4dffdbae37bf3fc"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# carico il file json su data\n",
    "with open('inglese.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# convert json a dataframe\n",
    "df = pd.json_normalize(data)\n",
    "\n",
    "# salvo il file csv\n",
    "df.to_csv('inglese.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T13:18:58.828609Z",
     "start_time": "2024-01-20T13:18:58.118389400Z"
    }
   },
   "id": "744e6ad9c987f03f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
