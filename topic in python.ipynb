{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Da qui si può selezionare la lingua per cui fare l'analisi\n",
    "# lingue selezionabili: portoghese, spagnolo, tedesco, italiano, francese, inglese\n",
    "lingua_selezionata = 'spagnolo'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7747273b25d986ac"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Topic modeling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81f9c6b9a03bba9e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''TOPIC MODELING PER LINGUA'''\n",
    "import json\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim import corpora, models\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "# seleziona la lingua in base a quella selezionata ad inizio file\n",
    "with open(lingua_selezionata + '.json', 'r') as f:\n",
    "    tweets_data = json.load(f)\n",
    "    \n",
    "# analisi della topic modelling\n",
    "# seleziona la lingua in base a quella selezionata ad inizio file\n",
    "match lingua_selezionata:\n",
    "    case 'portoghese':\n",
    "        selected_language = 'portuguese'\n",
    "        stopwords = ['nuclear','https','http','co','amp','rt']\n",
    "    case 'spagnolo':\n",
    "        selected_language = 'spanish'\n",
    "        stopwords = ['nucleares','nuclear','https','http','co','amp','rt']\n",
    "    case 'tedesco':\n",
    "        selected_language = 'german'\n",
    "        stopwords = ['nuklearia','https','http','co','amp','rt']\n",
    "    case 'italiano':\n",
    "        selected_language = 'italian'\n",
    "        stopwords = ['nucleare','https','http','co','amp','rt','poi','fa','della','delle','dell','essere','può','senza','solo','anche','così','quindi','dopo','fatto','fino','sì','cosa','parte','no','due','già','ora','nessuna','invece','tre','quale','quando','prima','tutto','stati','stata']\n",
    "    case 'francese':\n",
    "        selected_language = 'french'\n",
    "        stopwords = ['ça','a','nucléaire','nucléaires','https','http','co','amp','rt']\n",
    "    case 'inglese':\n",
    "        selected_language = 'english'\n",
    "        # stopwords che abbiamo deciso di non considerare nono presenti nella lista dalla libreria nltk\n",
    "        stopwords = ['https','http','co','it','would','the','amp','use','go','one','name','get','rt','nuclear']\n",
    "\n",
    "# Costruzione del corpus\n",
    "corpus = []\n",
    "for item in tweets_data:\n",
    "    # Tokenization del testo\n",
    "    parole = word_tokenize(item['text'].lower())\n",
    "    # rimuovi i simboli di punteggiatura o non parole e le stopwords\n",
    "    parole = [parola for parola in parole if parola.isalpha()]\n",
    "    parole = [parola for parola in parole if parola not in nltk.corpus.stopwords.words(selected_language)]\n",
    "    parole = [parola for parola in parole if parola not in stopwords]\n",
    "    corpus.append(parole)\n",
    "\n",
    "# Costruzione del dizionario\n",
    "dizionario = corpora.Dictionary(corpus)\n",
    "\n",
    "# Costruzione della matrice dei documenti\n",
    "doc_term_matrix = [dizionario.doc2bow(doc) for doc in corpus]\n",
    "\n",
    "# Costruzione del modello LDA\n",
    "lda_model = models.LdaMulticore(corpus = doc_term_matrix, num_topics=5, id2word=dizionario)\n",
    "\n",
    "# Visualizzazione dei topic\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "    \n",
    "# stampa grafica dei print_topic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import pyLDAvis.gensim\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_data_filepath = os.path.join('./ldavis_prepared_'+str(5))\n",
    "# # this is a bit time consuming - make the if statement True\n",
    "# # if you want to execute visualization prep yourself\n",
    "if 1 == 1:\n",
    "    LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, doc_term_matrix, dizionario)\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath, 'rb') as f:\n",
    "    LDAvis_prepared = pickle.load(f)\n",
    "pyLDAvis.save_html(LDAvis_prepared, './ldavis_prepared_'+ str(5) +'.html')\n",
    "LDAvis_prepared"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3615101adc61783"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
